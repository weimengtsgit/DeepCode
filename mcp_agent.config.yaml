$schema: ./schema/mcp-agent.config.schema.json
# 使用 bocha-mcp 中文搜索服务器 (已修复)
default_search_server: bocha-mcp
document_segmentation:
  enabled: false
  size_threshold_chars: 50000
execution_engine: asyncio
logger:
  level: info
  path_settings:
    path_pattern: logs/mcp-agent-{unique_id}.jsonl
    timestamp_format: '%Y%m%d_%H%M%S'
    unique_id: timestamp
  progress_display: true
  transports:
  - console
  - file
mcp:
  servers:
    # bocha-mcp 中文搜索引擎
    bocha-mcp:
      args:
      - D:\code\open\DeepCode-main\tools\bocha_search_server.py
      command: D:\code\open\DeepCode-main\.venv\Scripts\python.exe  # 使用虚拟环境的 Python (之前是 python3)
      env:
        BOCHA_API_KEY: 'sk-c305d8000c0645d1861147114981aad9'
        PYTHONPATH: D:\code\open\DeepCode-main

    brave:
      command: "node"
      args: [ "C:\\Users\\PC\\AppData\\Roaming\\npm\\node_modules\\@modelcontextprotocol\\server-brave-search\\dist\\index.js" ]
      env:
        # 请替换为您的 Brave API 密钥，从 https://brave.com/search/api/ 获取
        BRAVE_API_KEY: 'YOUR_BRAVE_API_KEY_HERE'
    filesystem:
      command: "node"
      args: [ "C:\\Users\\PC\\AppData\\Roaming\\npm\\node_modules\\@modelcontextprotocol\\server-filesystem\\dist\\index.js", "." ]

    code-implementation:
      args:
      - D:\code\open\DeepCode-main\tools\code_implementation_server.py
      command: D:\code\open\DeepCode-main\.venv\Scripts\python.exe
      description: Paper code reproduction tool server - provides file operations,
        code execution, search and other functions
      env:
        PYTHONPATH: D:\code\open\DeepCode-main
    code-reference-indexer:
      args:
      - D:\code\open\DeepCode-main\tools\code_reference_indexer.py
      command: D:\code\open\DeepCode-main\.venv\Scripts\python.exe
      description: Code reference indexer server - Provides intelligent code reference
        search from indexed repositories
      env:
        PYTHONPATH: D:\code\open\DeepCode-main
    command-executor:
      args:
      - D:\code\open\DeepCode-main\tools\command_executor.py
      command: D:\code\open\DeepCode-main\.venv\Scripts\python.exe
      env:
        PYTHONPATH: D:\code\open\DeepCode-main
    document-segmentation:
      args:
      - D:\code\open\DeepCode-main\tools\document_segmentation_server.py
      command: D:\code\open\DeepCode-main\.venv\Scripts\python.exe
      description: Document segmentation server - Provides intelligent document analysis
        and segmented reading to optimize token usage
      env:
        PYTHONPATH: D:\code\open\DeepCode-main
    fetch:
      args:
      - mcp-server-fetch
      command: uvx
    file-downloader:
      args:
      - D:\code\open\DeepCode-main\tools\pdf_downloader.py
      command: D:\code\open\DeepCode-main\.venv\Scripts\python.exe
      env:
        PYTHONPATH: D:\code\open\DeepCode-main
    github-downloader:
      args:
      - D:\code\open\DeepCode-main\tools\git_command.py
      command: D:\code\open\DeepCode-main\.venv\Scripts\python.exe
      env:
        PYTHONPATH: D:\code\open\DeepCode-main
# LLM Provider Priority (选择使用哪个LLM / Choose which LLM to use)
# Options: "anthropic", "google", "openai"
# If not set or provider unavailable, will fallback to first available provider
llm_provider: "openai"  # 设置为 "google", "anthropic", 或 "openai"

openai:
  base_max_tokens: 40000
  # 阿里云千问模型 (Qwen)
#  default_model: qwen-max  # 千问最强模型,推荐使用
#  default_model: qwen-plus  # 性价比高的选择
  # default_model: qwen-turbo  # 速度快,成本低
  # default_model: qwen-long  # 支持长上下文
  default_model: gemini-3-pro-preview
#  default_model: anthropic/claude-sonnet-4.5
  # default_model: openai/gpt-oss-120b
  # default_model: deepseek/deepseek-v3.2-exp
  # default_model: moonshotai/kimi-k2-thinking
  reasoning_effort: low  # Only for thinking models
  max_tokens_policy: adaptive
  retry_max_tokens: 32768

# Configuration for Google AI (Gemini)
google:
  default_model: "gemini-3-pro-preview"

anthropic:
  default_model: "claude-haiku-4-5-20251001"
  # 增加 max_tokens 以避免响应被截断导致工具调用参数不完整
  max_tokens: 16384

planning_mode: traditional