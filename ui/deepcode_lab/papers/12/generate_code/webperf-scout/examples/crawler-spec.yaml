---
# WebPerf Scout: Crawler Performance Specification Example
# Demonstrates comprehensive web crawling and performance testing configuration

global:
  name: "Example Crawler Performance Test"
  description: "Comprehensive web crawling performance analysis"
  timeout: 300  # 5 minutes total test duration
  log_level: "info"

crawler:
  seed_url: "https://example.com"
  max_depth: 3  # Maximum link traversal depth
  max_pages: 50  # Maximum number of pages to crawl
  allowed_domains:  # Restrict crawling to specific domains
    - "example.com"
    - "www.example.com"
  
  exclusions:  # URLs or patterns to exclude from crawling
    - "*.pdf"
    - "*.jpg"
    - "*/admin/*"

performance:
  thresholds:
    lcp_max: 2500  # Largest Contentful Paint (ms)
    fcp_max: 1800  # First Contentful Paint (ms)
    tti_max: 3500  # Time to Interactive (ms)
    cls_max: 0.1   # Cumulative Layout Shift
    tbt_max: 200   # Total Blocking Time (ms)

  scoring:
    weights:
      lcp: 0.25
      fcp: 0.15
      tti: 0.20
      cls: 0.15
      tbt: 0.25

browser:
  type: "chromium"  # Preferred browser for testing
  viewport:
    width: 1920
    height: 1080
  device_emulation: "Desktop"

network:
  conditions:
    - name: "4G"
      download_speed: 4000  # Kbps
      upload_speed: 1000    # Kbps
      latency: 50           # ms
    - name: "3G"
      download_speed: 1600  # Kbps
      upload_speed: 768     # Kbps
      latency: 100          # ms

advanced:
  parallel_crawl: true
  max_concurrent_pages: 5
  retry_attempts: 2
  timeout_per_page: 30  # seconds

reporting:
  formats:
    - "json"
    - "html"
    - "markdown"
  output_directory: "./crawl_reports"
  include_screenshots: true
  performance_trend_tracking: true

security:
  user_agent: "WebPerfScout/1.0 Crawler"
  ssl_verification: true
  proxy: null  # Optional proxy configuration

monitoring:
  alerts:
    performance_drop_threshold: 20  # Percentage drop to trigger alert
    email_notifications: 
      - "admin@example.com"